# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.

import os
import glob
from snakemake.utils import min_version

min_version("9.1.6")


configfile: "config/config.yaml"


# list all subfolders in input_dir
sample_dirs = [
    sample
    for sample in os.listdir(config["input_dir"])
    if os.path.isdir(os.path.join(config["input_dir"], sample))
    and "unclassified" not in sample.lower()
]


# include: "rules/01-cat_fastq.smk"
# include: "rules/02-qfilter.smk"
# concat totalreads files here
# include: "rules/03-rename_samples.smk"
include: "rules/01-sample_prep.smk"
include: "rules/02-primertrim.smk"
include: "rules/03-subsample.smk"
include: "rules/04-denoise.smk"
include: "rules/05-sintax.smk"
include: "rules/06-append_asv_counts.smk"
include: "rules/07-abund_table.smk"

# include: "rules/02-denoise.smk"
# include: "rules/03-rename_known_zotus.smk"
# include: "rules/05-abund_table.smk"

# Define subsets outside any rule
subset_dirs = ["all_reads"] + [
    f"sample_size_{s}"
    for s in config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000])
] + ["sample_size_all_reads"]


###############################################################
# Final output targets
###############################################################

rule all:
    input:
        # --- Pre-subsampling statistics ---
        expand(
            os.path.join(config["tmp_dir"], "totalreads", "{sample}_totalreads.csv"),
            sample=sample_dirs
        ),
        expand(
            os.path.join(config["tmp_dir"], "totalreads_trimmed", "{sample}_totaltrimmedreads.csv"),
            sample=sample_dirs
        ),

        # --- Subsampling outputs (merged all samples) ---
        expand(
            os.path.join(
                config["output_dir"],
                "03-subsample",
                "sample_size_{size}",
                "all_samples_subsampled_{size}.fastq"
            ),
            size=config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000]) + ["all_reads"]
        ),
        os.path.join(config["output_dir"], "03-subsample", "subsample_summary.tsv"),

        # --- Denoising outputs ---
        expand(
            os.path.join(config["output_dir"], "04-denoise", "sample_size_{subset}", "zOTUs.fa"),
            subset=config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000]) + ["all_reads"]
        ),

        # --- Taxonomy assignment ---
        expand(
            os.path.join(config["output_dir"], "05-sintax", "sample_size_{subset}", "zOTUs.sintax"),
            subset=config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000]) + ["all_reads"]
        ),

        # --- Post-summary outputs ---
        os.path.join(config["output_dir"], "subsample_summary_with_ASVs.tsv"),
        os.path.join(config["output_dir"], "subsample_summary_ASV_matches.tsv"),
        # --- Abundance table ---
        expand(
            os.path.join(config["output_dir"], "07-abund_table", "abund_table_{subset}.tsv"),
            subset=config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000]) + ["all_reads"]
        ),



#rule all:
#    input:
#        # --- Pre-subsampling statistics ---
#        expand(
#            os.path.join(config["tmp_dir"], "totalreads", "{sample}_totalreads.csv"),
#            sample=sample_dirs
#        ),
#        expand(
#            os.path.join(config["tmp_dir"], "totalreads_trimmed", "{sample}_totaltrimmedreads.csv"),
#            sample=sample_dirs
#        ),
#
#        # --- Subsampling outputs ---
#        #expand(
#        #    os.path.join(config["output_dir"], "subsample", "sample_size_{size}", "{sample}_subsampled_{size}.fastq"),
#        #    sample=sample_dirs,
#        #    size=config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000, 400000])
#        #),
#        os.path.join(config["output_dir"], "subsample", "subsample_summary.tsv"),
#
#        # --- Denoising outputs ---
#        expand(
#            os.path.join(config["output_dir"], "04-denoise", "{subset}", "zOTUs.fa"),
#            subset=subset_dirs
#        ),
#
#        # --- Taxonomy assignment ---
#        expand(
#            os.path.join(config["output_dir"], "05-sintax", "{subset}", "zOTUs.sintax"),
#            subset=subset_dirs
#        ), 
#        # --- Subsampling outputs ---
#        expand(
#            os.path.join(config["output_dir"], "subsample", "sample_size_{size}", "{sample}_subsampled_{size}.fastq"),
#            sample=sample_dirs,
#            size=config.get("subsample_sizes", [10000, 20000, 50000, 100000, 200000, 400000])
#        ),
#        os.path.join(config["output_dir"], "subsample_summary_with_ASVs.tsv"),
#        os.path.join(config["output_dir"], "subsample_summary_ASV_matches.tsv"),
#
#